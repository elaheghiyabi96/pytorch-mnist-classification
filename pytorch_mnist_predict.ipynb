{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3370365788226824\n",
      "Epoch 2, Loss: 0.15361766518155204\n",
      "Epoch 3, Loss: 0.10748855500960591\n",
      "Epoch 4, Loss: 0.08265391180315601\n",
      "Epoch 5, Loss: 0.06603394946141014\n",
      "Test Accuracy: 97.36%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch                # Import the main PyTorch library\n",
    "import torch.nn as nn       # Import the neural network module of PyTorch\n",
    "import torch.optim as optim # Import the optimization module for training the model\n",
    "from torchvision import datasets, transforms  # Import the datasets and transformations from torchvision\n",
    "from torch.utils.data import DataLoader  # Import DataLoader to handle data loading\n",
    "\n",
    "# Data preparation\n",
    "transform = transforms.Compose([transforms.ToTensor()])  # Create a transformation to convert images to tensors\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)  # Load training data for MNIST, apply the transformation\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)  # Load test data for MNIST, apply the transformation\n",
    "\n",
    "# DataLoader to load data in batches for training and testing\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)  # Create a DataLoader for training data, with batch size 64 and shuffle enabled\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)  # Create a DataLoader for test data, with batch size 64 and shuffle disabled\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()  # Initialize the base class\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # Fully connected layer from 28x28 (784 pixels) to 128 neurons\n",
    "        self.relu = nn.ReLU()  # ReLU activation function\n",
    "        self.fc2 = nn.Linear(128, 10)       # Fully connected layer from 128 neurons to 10 outputs (one for each class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image from 28x28 to 784 pixels (vector)\n",
    "        x = self.fc1(x)          # Pass through the first fully connected layer\n",
    "        x = self.relu(x)         # Apply ReLU activation\n",
    "        x = self.fc2(x)          # Pass through the second fully connected layer (output layer)\n",
    "        return x  # Return the output of the model\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss function for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate of 0.001\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(5):  # Loop over the training dataset for 5 epochs\n",
    "    total_loss = 0  # Initialize the total loss for this epoch\n",
    "    for images, labels in train_loader:  # Loop over batches of images and labels from the training data\n",
    "        optimizer.zero_grad()  # Reset the gradients from the previous iteration\n",
    "        outputs = model(images)  # Get the model's output for the input images\n",
    "        loss = criterion(outputs, labels)  # Calculate the loss between predicted outputs and actual labels\n",
    "        loss.backward()  # Backpropagate the loss to compute gradients\n",
    "        optimizer.step()  # Update the model weights using the optimizer\n",
    "        total_loss += loss.item()  # Accumulate the loss for this epoch\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Testing the model\n",
    "correct = 0  # Initialize the counter for correct predictions\n",
    "total = 0  # Initialize the counter for total number of predictions\n",
    "with torch.no_grad():  # Disable gradient computation for testing (this saves memory and computation)\n",
    "    for images, labels in test_loader:  # Loop over batches of images and labels from the test data\n",
    "        outputs = model(images)  # Get the model's output for the input images\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest probability (the predicted class)\n",
    "        total += labels.size(0)  # Increase the total number of predictions\n",
    "        correct += (predicted == labels).sum().item()  # Increase the number of correct predictions\n",
    "\n",
    "# Print the accuracy of the model on the test dataset\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 6\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch  # Import PyTorch library\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for plotting images\n",
    "\n",
    "# Define the device for using GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # If a GPU is available, use it; otherwise, use CPU\n",
    "\n",
    "# Get index 100 from the test data\n",
    "index = 100  # Define the index to fetch the 100th image from the test dataset\n",
    "image, label = test_data[index]  # Get the image and its true label at the given index from the test data\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")  # Squeeze the image tensor to remove any extra dimensions and display it in grayscale\n",
    "plt.title(f\"True Label: {label}\")  # Set the title of the image plot to show the true label of the image\n",
    "plt.show()  # Display the image plot\n",
    "\n",
    "# Send the model to the appropriate device (GPU or CPU)\n",
    "model.to(device)  # Move the model to the device (GPU or CPU) that was defined earlier\n",
    "\n",
    "# Make a prediction with the model\n",
    "model.eval()  # Change the model to evaluation mode (turn off dropout and batch normalization)\n",
    "with torch.no_grad():  # Disable gradient computation for inference (saves memory and computation)\n",
    "    output = model(image.unsqueeze(0).to(device))  # Pass the image to the model (add a batch dimension using unsqueeze and move to the device)\n",
    "    _, predicted = torch.max(output, 1)  # Get the predicted class by finding the index of the maximum value in the output tensor\n",
    "\n",
    "# Print the predicted label\n",
    "print(f\"Predicted Label: {predicted.item()}\")  # Print the predicted label as a scalar value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
